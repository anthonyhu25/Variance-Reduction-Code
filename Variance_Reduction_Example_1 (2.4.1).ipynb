{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtolY8Awf2YYDk5dSU+MoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthonyhu25/Variance-Reduction-Code/blob/main/Variance_Reduction_Example_1%20(2.4.1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jN1QXVu3buo2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import random\n",
        "from numpy import linalg\n",
        "import math\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import rv_continuous, rv_discrete\n",
        "from scipy.stats._distn_infrastructure import rv_frozen\n",
        "from scipy.special import logsumexp\n",
        "import scipy.integrate\n",
        "import warnings\n",
        "import sys\n",
        "import statistics\n",
        "import pandas as pd\n",
        "from IPython.display import display, Math, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1 (Normal target distribution with normal distribution and student-t distribution proposals)"
      ],
      "metadata": {
        "id": "VccuSTLhb6Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we are estimating the expected value of $F(x) = x$, with the target distribution $\\pi(x)\\sim N\\bigl(x\\mid 0,1 )$. We will use two proposal distributions: $N\\bigl(y\\mid 0,\\sigma^2\\bigr)$ and a 0-mean student-t distribution with $t_\\nu (y)$. Note that $\\sigma^2$ and $\\nu$ are not fixed in either proposal distribution. We will simulate the posterior with different values of each parameter to see how $\\mu_{n,IMCV}$ (the posterior mean of the independent Metropolis-Hastings Algorithm with the control variate for $n$ samples) changes as we increase both parameters.\n",
        "\n",
        "For each possible values of $\\sigma^2$ and $\\nu$, we will simulate 5000 values (as noted in the paper) for 20 times. Then, we will find $\\mu_{n, MC*}$ (the mean of the conditional Monte Carlo estimator for $n$ samples) of the algorithm, and calculate the VRF (variance reduciton factor) using the below formula:\n",
        "\n",
        "$$VRF =\n",
        "  \\frac{%\n",
        "    \\displaystyle\n",
        "    \\sum_{i=1}^T\n",
        "      \\Bigl(\n",
        "        \\mu_{n,\\mathrm{MC}^*}^{(i)}\n",
        "        \\;-\\;\n",
        "        \\frac{1}{T}\\,\\sum_{j=1}^T \\mu_{n,\\mathrm{MC}^*}^{(j)}\n",
        "      \\Bigr) ^2\n",
        "  }{%\n",
        "    \\displaystyle\n",
        "    \\sum_{i=1}^T\n",
        "      \\Bigl(\n",
        "        \\mu_{n,\\mathrm{IMCV}}^{(i)}\n",
        "        \\;-\\;\n",
        "        \\frac{1}{T}\\,\\sum_{j=1}^T \\mu_{n, \\mathrm{IMCV}^*}^{(j)}\n",
        "      \\Bigr) ^2\n",
        "  }\n",
        "$$\n"
      ],
      "metadata": {
        "id": "w7oDXXkLb_uK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we need to explicitly calculate $E_{q}(F)$, where $F(x) = x$.\n",
        "Since $q(y)$ are the $N\\bigl(y\\mid 0,\\sigma^2\\bigr)$ and the $0$-mean student-t distribution with $t_\\nu (y)$, we just need to find the first moment of these two distributions. However, since both distributions have 0 mean, then $ùîº_{q}(F) = ùîº_{q}(x) =  0$ for both proposal distributions. Note that $f(x) ‚àù \\frac{-\\mu x^2 }{2œÉ^2}$, where $\\mu$ and $\\sigma$ are parameters of $\\pi(x)$. So, $f(x)$ simplifies to $\\frac{-x^2}{2}$, for all values drawn from $\\pi(x)$. Also note that both proposal densities are greater than 0, and hence we do not have to worry about the case when $q(y)$ equals 0."
      ],
      "metadata": {
        "id": "inYcU53XcD3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def univariate_independent_metro(n_simulations, T_iterations, burn_in, pi_distribution, q_distribution, F_function):\n",
        "  # First check to see if pi and q are both scipy distribution objects\n",
        "  for name, dist in [(\"q_distribution\", q_distribution), (\"pi_distribution\", pi_distribution)]:\n",
        "      if not all(hasattr(dist, attr) for attr in [\"rvs\", \"pdf\", \"expect\"]):\n",
        "          raise ValueError(\n",
        "              f\"{name} must be a valid frozen scipy.stats distribution with .rvs(), .pdf(), and .expect(). Got: {type(dist)}\"\n",
        "          )\n",
        "  mu_IMCV_list = []\n",
        "  # Calculate expectation of F with respect to q\n",
        "  F_q_expect = q_distribution.expect(F_function)\n",
        "  # Define our F() in this example(which is F(x) = x)\n",
        "  ## Note: this function is not related to the f(x) function in the alpha acceptance ratio\n",
        "  for i in range(T_iterations):\n",
        "    # This is for the state of the chain: Just to keep in track for proposing and sampling new values\n",
        "    ## It is not really necessary for me to initiate a list for a chain when it comes to calculating mu_IMCV\n",
        "    ## and mu_MC, but it helps with me for analyzing the movement of the chain in case I coded something wrong\n",
        "    X_list = []\n",
        "    Y_list = []\n",
        "    alpha_chain = []\n",
        "    # MCMC algorithm: iterate through number of simulations\n",
        "    for j in range(n_simulations + burn_in):\n",
        "      if(len(X_list) == 0):\n",
        "        # Initiate the Chain by Sampling from Proposal Distribution\n",
        "        X_list.append(float(q_distribution.rvs()))\n",
        "        Y_list.append(float(q_distribution.rvs()))\n",
        "        alpha_chain.append(1)\n",
        "      else:\n",
        "        # X in each iteration is the current state of the chain.\n",
        "        X = float(X_list[-1])\n",
        "        # Y in each iteration is drawn from the proposal density\n",
        "        Y = float(q_distribution.rvs())\n",
        "        # Calculate acceptance ratio\n",
        "        ## find alpha, and then generate uniform distribution to accept or reject the sample\n",
        "        numerator_alpha = pi_distribution.pdf(Y) * q_distribution.pdf(X)\n",
        "        denominator_alpha = pi_distribution.pdf(X)* q_distribution.pdf(Y)\n",
        "        alpha = min(1, numerator_alpha / denominator_alpha)\n",
        "        # Append Y to the Y_list, for final calculation of the Mu-values\n",
        "        Y_list.append(Y)\n",
        "        alpha_chain.append(alpha)\n",
        "        # Generate uniform RV to accept/reject Y\n",
        "        ## if U is less than alpha, then we accept new sample(Y) as the next state\n",
        "        ## Otherwise, we stay at the current state(X)\n",
        "        u = np.random.uniform(low = 0, high = 1)\n",
        "        if(u <= alpha):\n",
        "          X_list.append(Y)\n",
        "        else:\n",
        "          X_list.append(X)\n",
        "      # Throw away the burn-in samples\n",
        "    X_list = X_list[burn_in:]\n",
        "    Y_list = Y_list[burn_in:]\n",
        "    alpha_chain = alpha_chain[burn_in:]\n",
        "    # Now we calculate the approximations of mu_IMCV and mu_MC\n",
        "    ## Note that mu_MC is the basic conditional MH algorithm: just feed the chain state (X_i) into the function F() and look for its average\n",
        "    ## Calculation of mu_IMCV is relatively harder, but still quite simple.\n",
        "    mu_IMCV = mu_calculation(X_list, Y_list, alpha_chain, is_IMCV = True, F_function = F_function, q_distribution = q_distribution)\n",
        "    mu_IMCV_list.append(float(mu_IMCV))\n",
        "  return mu_IMCV_list, X_list, Y_list, alpha_chain\n",
        "\n",
        "# Helper function for calculation of mu_IMCV\n",
        "## Note that q has to be a scipy.stats.___ distribution. Cannot use numpy\n",
        "def mu_calculation(X_chain, Y_chain, alpha_chain, is_IMCV, F_function, q_distribution):\n",
        "  # Check to see if q is a scipy distribution\n",
        "  if not all(hasattr(q_distribution, attr) for attr in [\"rvs\", \"pdf\", \"expect\"]):\n",
        "      warnings.warn(\"Warning: q is not a valid scipy.stats frozen distribution.\")\n",
        "      sys.exit(1)\n",
        "  mu = 0\n",
        "  F_q_expect = q_distribution.expect(F_function)\n",
        "  if is_IMCV == True:\n",
        "    for i in range(len(X_chain)):\n",
        "      mu += F_function(X_chain[i]) + alpha_chain[i] * (F_function(Y_chain[i]) - F_function(X_chain[i])) - (F_function(Y_chain[i]) - F_q_expect)\n",
        "    mu = mu / len(X_chain)\n",
        "  else:\n",
        "    mu = np.mean([F_function(x) for x in X_chain])\n",
        "  return mu\n",
        "\n",
        "  ## Helper function for plotting X_i, Y_i, and alpha(X_i, Y_i)\n",
        "def plot_traces(X_chain, Y_chain, alpha_chain, q_distribution=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
        "\n",
        "    axs[0].plot(X_chain, label='X Chain')\n",
        "    axs[0].set_ylabel('X values')\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].plot(Y_chain, label='Y Chain', color='orange')\n",
        "    axs[1].set_ylabel('Y values')\n",
        "    axs[1].legend()\n",
        "\n",
        "    axs[2].plot(alpha_chain, label='Alpha', color='green')\n",
        "    axs[2].set_xlabel('Iteration')\n",
        "    axs[2].set_ylabel('Alpha values')\n",
        "    axs[2].legend()\n",
        "\n",
        "    if q_distribution is not None:\n",
        "        dist_name = q_distribution.dist.name  # e.g. 'norm' or 't'\n",
        "        params = ', '.join(f'{k}={v}' for k, v in q_distribution.kwds.items())\n",
        "        plt.suptitle(f\"Trace Plots (q: {dist_name}({params}))\", fontsize=14)\n",
        "    else:\n",
        "        plt.suptitle(\"Trace Plots of MCMC Chains\", fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u8HbGbUCcJsA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def univariate_symmetric_MH_sampler(n_simulations, T_iterations, burn_in, pi_distribution, F_function):\n",
        "  # Check to see if pi_distribution is valid\n",
        "  required = [\"rvs\", \"pdf\", \"expect\"]\n",
        "  if not all(hasattr(pi_distribution, attr) for attr in required):\n",
        "    raise ValueError(\n",
        "        f\"pi_distribution must be a frozen scipy.stats distribution with \"\n",
        "        f\".rvs(), .pdf(), and .expect(). Got: {type(pi_distribution)}\"\n",
        "    )\n",
        "  # Initiate sampler\n",
        "  mu_MC = []\n",
        "  for i in range(T_iterations):\n",
        "    X_chain = []\n",
        "    for j in range(n_simulations):\n",
        "      if len(X_chain) == 0:\n",
        "        # Accept with probability of 1\n",
        "        Y = pi_distribution.rvs()\n",
        "        X_chain.append(float(F_function(Y)))\n",
        "      else:\n",
        "        Y = float(pi_distribution.rvs())\n",
        "        X = float(X_chain[-1])\n",
        "        # Acceptance/Rejection\n",
        "        U = np.random.uniform(0, 1)\n",
        "        acceptance_ratio = min(1, pi_distribution.pdf(Y)/pi_distribution.pdf(X))\n",
        "        if U < acceptance_ratio:\n",
        "          X_chain.append(Y)\n",
        "        else:\n",
        "          X_chain.append(X)\n",
        "      # Toss out burn-in samples\n",
        "      X_chain = X_chain[burn_in:]\n",
        "      mu_MC_i = np.mean([F_function(X_chain[i]) for i in range(len(X_chain))])\n",
        "      mu_MC.append(mu_MC_i)\n",
        "  return mu_MC"
      ],
      "metadata": {
        "id": "9ipKxNSkcNbf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Sigmas given in the paper\n",
        "## Trying to recreate the graphs in the paper to make sure my implementation is correct\n",
        "sigmas = [1.1, 1.2, 1.3, 1.4, 1.5, 1.6]\n",
        "IMCV_lists = []\n",
        "MH_lists = []\n",
        "VRF_list = []\n",
        "T = 100\n",
        "for k in sigmas:\n",
        "  A = univariate_independent_metro(n_simulations = 5000, T_iterations = T, burn_in = 1000,\n",
        "                               pi_distribution = scipy.stats.norm(loc = 0, scale = 1),\n",
        "                               q_distribution = scipy.stats.norm(loc = 0, scale = k),\n",
        "                               F_function = lambda x: x)\n",
        "  IMCV_estimates = A[0]\n",
        "  # It's not necessary to plot these, as they don't have them in the paper, but the more visualizations about how the chain performed, the better in my opinion\n",
        "  plot_traces(A[1], A[2], A[3], q_distribution = scipy.stats.norm(loc = 0, scale = k))\n",
        "  # mu_IMCV\n",
        "  IMCV_lists.append(A[0])\n",
        "  # mu_MC*\n",
        "  ## Run symmetric MH\n",
        "  B = univariate_symmetric_MH_sampler(n_simulations = 5000, T_iterations = T, burn_in = 1000,\n",
        "                                      pi_distribution = scipy.stats.norm(loc = 0, scale = 1),\n",
        "                                      F_function = lambda x: x)\n",
        "  MC_estimates = B\n",
        "  MH_lists.append(MC_estimates)\n",
        "  # VRF calculation\n",
        "  VRF_list.append(statistics.variance(IMCV_estimates)/statistics.variance(MC_estimates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2Deo-I4tcP2M",
        "outputId": "3fe17756-f920-4073-8afd-1767a0446f47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2190964808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigmas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m  A = univariate_independent_metro(n_simulations = 5000, T_iterations = T, burn_in = 1000,\n\u001b[0m\u001b[1;32m     10\u001b[0m                               \u001b[0mpi_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                               \u001b[0mq_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3747974571.py\u001b[0m in \u001b[0;36munivariate_independent_metro\u001b[0;34m(n_simulations, T_iterations, burn_in, pi_distribution, q_distribution, F_function)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Calculate acceptance ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m## find alpha, and then generate uniform distribution to accept or reject the sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnumerator_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mdenominator_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mq_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerator_alpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0mcond0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m         \u001b[0mcond1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond0\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcond1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_support_mask\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/_ufunc_config.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0m_extobj_contextvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the mu_IMCV estimates. In paper\n",
        "plt.boxplot(IMCV_lists, tick_labels = sigmas, showfliers=False, whis=[0, 100])\n",
        "plt.xlabel(\"$\\sigma$\")\n",
        "plt.ylabel(\"Estimate of mu_IMCV\")\n",
        "plt.show()\n",
        "# Plotting the mu_MC* estimates. Not in the paper, but just for comparison\n",
        "plt.boxplot(MH_lists, tick_labels = sigmas, showfliers=False, whis=[0, 100])\n",
        "plt.xlabel(\"$\\sigma$\")\n",
        "plt.ylabel(\"Estimate of mu_MC*\")\n",
        "plt.show()\n",
        "# Haven't figured out how to calculate the bounds yet, but I have the curve of the base log(VRF) from the simulations\n",
        "plt.plot(sigmas, [math.log(i) for i in VRF_list])\n",
        "plt.xlabel(\"$\\sigma$\")\n",
        "plt.ylabel(\"Log(VRF)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OhdvUzfFcdMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_2 of v (degrees of freedom parameters for T-distribution) given in paper\n",
        "log_2_v = [1.6, 2.6, 3.6, 4.6, 5.6, 6.6]\n",
        "v = [2 ** i for i in log_2_v]\n",
        "print(v)\n",
        "IMCV_t_distribution_lists = []\n",
        "MH_t_distribution_lists = []\n",
        "VRF_t_distribution_lists = []\n",
        "T = 100\n",
        "for k in v:\n",
        "  X = univariate_independent_metro(n_simulations = 5000, T_iterations = T, burn_in = 1000,\n",
        "                               pi_distribution = scipy.stats.norm(loc = 0, scale = 1),\n",
        "                               q_distribution = scipy.stats.t(df = k),\n",
        "                               F_function = lambda x: x)\n",
        "  plot_traces(X[1], X[2], X[3], q_distribution = scipy.stats.t(df = k))\n",
        "  IMCV_t_distribution_lists.append(X[0])\n",
        "  Y = univariate_symmetric_MH_sampler(n_simulations= 5000, T_iterations = T, burn_in = 1000,\n",
        "                              pi_distribution=scipy.stats.norm(loc = 0, scale = 1),\n",
        "                              F_function= lambda x: x)\n",
        "  MH_t_distribution_lists.append(Y)\n",
        "  VRF_t_distribution_lists.append(statistics.variance(X[0])/statistics.variance(Y))"
      ],
      "metadata": {
        "id": "aa4XgMgGcgye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(IMCV_t_distribution_lists, tick_labels = log_2_v, showfliers=False, whis=[0, 100])\n",
        "plt.xlabel(\"$log_2(v)$\")\n",
        "plt.ylabel(\"Estimate of mu_IMCV\")\n",
        "plt.show()\n",
        "\n",
        "plt.boxplot(MH_t_distribution_lists, tick_labels = log_2_v, showfliers=False, whis=[0, 100])\n",
        "plt.xlabel(\"$log_2(v)$\")\n",
        "plt.ylabel(\"Estimate of mu_MC*\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(log_2_v, [math.log(i) for i in VRF_t_distribution_lists])\n",
        "plt.xlabel(\"$log_2(v)$\")\n",
        "plt.ylabel(\"Log(VRF)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IKltPLYtdr8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}